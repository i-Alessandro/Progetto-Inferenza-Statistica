---
title: "Regressione Logistica"
author: "Alessandro Wiget"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Librerie

```{r, results='hide', warning= FALSE, message=FALSE}
library(readxl)
library(dplyr)
library( faraway )
library( leaps )
library(MASS)
library( GGally)
library(BAS)
library(rgl)
library(corrplot)
library(pscl)
```

## Il Dataset

Prima di tutto definiamo la working directory:

IMPORTANTE! Cambiare la directoy a seconda del pc.

Importiamo il Dataset, presente nella cartella `Dati/`:

```{r}
setwd("C:/Users/alewi/Documents/University/HKUST & PoliMi/II Semestre/Inferenza Statistica/Progetto")
df <- read_excel("./Dati/Dropout20240226_IngMate.xlsx")
#View(df)
```

## Regressione Logistica

Consideriamo innanzitutto solo gli studenti con carriere terminate, cioè o che si sono laureati o che hanno abbandonato il corso di studio:

```{r}
df$career_anonymous_id <- NULL
df$career_time <- NULL
df$stud_career_degree_start_id <- NULL

filtered_df <- df %>% filter(stud_career_status != 'A')
```

Selezioniamo dal dataset le variabili numeriche:

```{r}
numerical_vars <- sapply(filtered_df, is.numeric)  # Find numeric columns
numerical_df <- filtered_df[, numerical_vars]  # Subset dataframe with numeric columns
numerical_df = na.omit(numerical_df)
```

Osserviamo se esistono correlazioni significative fra i dati numerici:

```{r}
X = numerical_df[, -4]
corrplot(cor(X), method='color')
```

Effettuiamo la regressione logistica fra le variabili numeriche del dataset:

```{r}
# Create a formula for linear model
formula <- as.formula(paste("dropout ~", paste(names(numerical_df[,-which(names(numerical_df) == "dropout")]), collapse = " + ")))

# Fit the linear model
model <- glm(formula, data = numerical_df)

# Print the summary of the model
summary(model)
```

Cerchiamo di trovare il miglior modello con un Automatic Selection Method. Massimizziamo l'adjr2 con la funzione `leaps()`, ovvero un algoritmo Branch and Bound per trovare tali modelli.

```{r, message=FALSE}
x = model.matrix( model ) [ , -1 ]
y = numerical_df$dropout

adjr = leaps( x, y, method = "adjr2" )
names(adjr)
```

```{r}
bestmodel_adjr2_ind = which.max( adjr$adjr2 )
adjr$which[ bestmodel_adjr2_ind, ] 

maxadjr(adjr,50)
```

Dal momento che non è presente una variazione significativa dell'adjr2 dei primi modelli, cerchiamo dunque di minimizzare il numero di variabili utilizzate. La scelta ricade dunque sul modello che contiene le features delle colonne `4,5,8,9`.

Il modello diventa dunque:

```{r}
# Assuming 'df' is your dataframe and 'target' is your target variable
# Select only the columns you're interested in
selected_df <- numerical_df[, c(4,5,6,9,10)]

# Create a formula for the model
# This assumes that the first column is the target variable
formula <- paste("dropout ~", paste(names(selected_df[,-which(names(selected_df) == "dropout")]), collapse = " + "))

# Fit the model
model_opt <- glm(formula, data = selected_df, family = binomial)

# Print the summary of the model
summary(model_opt)

# adjr2 per il modello con interazione: (Usiamo McFadden)
pseudo_r2 <- pR2(model_opt)

pseudo_r2['McFadden']
```

Riferendoci alla tabella delle covariate presentata in precedenza, vogliamo capire se è possibile migliorare il modello introducendo una interazione fra le covariate che sono più correlate, ovvero `exa_cfu_pass` e `exa_grade_average`:

```{r}
# Assuming 'df' is your dataframe and 'target' is your target variable
# Select only the columns you're interested in
selected_df <- numerical_df[, c(4,5,6,9,10)]

# Create a formula for the model
# This assumes that the first column is the target variable
covariate <- paste("dropout ~", paste(names(selected_df[,-which(names(selected_df) == "dropout")]), collapse = " + "))

interazioni = " + exa_cfu_pass * exa_grade_average"

formula = as.formula(paste(covariate, interazioni))

# Fit the model
model_opt <- glm(formula, data = selected_df, family = binomial)

# Print the summary of the model
summary(model_opt)

# adjr2 per il modello con interazione: (Usiamo McFadden)
pseudo_r2 <- pR2(model_opt)

pseudo_r2['McFadden']
```

Notiamo un miglioramento dell'AIC, tuttavia adesso la feature `exa_cfu_pass` risulta superflua, procediamo quindi ad eliminarla:

```{r}
# Assuming 'df' is your dataframe and 'target' is your target variable
# Select only the columns you're interested in
selected_df <- numerical_df[, c(4,5,6,9,10)]

# Create a formula for the model
# This assumes that the first column is the target variable
covariate <- paste("dropout ~", paste(names(selected_df[,-which(names(selected_df) == "dropout")]), collapse = " + "))

interazioni = " + exa_cfu_pass * exa_grade_average"

rimuovere = "- exa_cfu_pass"

formula = as.formula(paste(covariate, interazioni, rimuovere))

# Fit the model
model_opt <- glm(formula, data = selected_df, family = binomial)

# Print the summary of the model
summary(model_opt)

# adjr2 per il modello con interazione: (Usiamo McFadden)
pseudo_r2 <- pR2(model_opt)

pseudo_r2['McFadden']
```

Confrontando i valori dell'adjusted R\^2 vediamo che l'aggiunta di una covariata data dal termine di interazioni, fa aumentare l'indice di pochi millesimi. Dunque non risulta vantaggioso il tradeoff e manteniamo il modello precedente.

## Predizione

Applichiamo adesso il modello lineare sugli studenti che non hanno ancora completato il loro percorso universitario:

```{r}
new_data = filtered_df <- df %>% filter(stud_career_status == 'A')
new_data_vars <- sapply(new_data, is.numeric)  # Find numeric columns
new_data <- new_data[, numerical_vars]  # Subset dataframe with numeric columns
new_data = new_data[,c(-4,-8)]
new_data = na.omit(new_data)

#View(new_data)

predicted_values <- predict(model_opt, newdata = new_data, type = "response")
plot(new_data$exa_cfu_pass, predicted_values, main="Predizione di dropout / CFU acquisiti nel primo semestre", 
     xlab="CFU sostenuti", 
     ylab="Predizione Dropout")

plot(new_data$exa_grade_average, predicted_values, main="Predizione di dropout / Media pesata nel primo semestre", 
     xlab="media pesata", 
     ylab="Predizione Dropout")
```
