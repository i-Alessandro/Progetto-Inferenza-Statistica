---
title: "Regressione Logistica"
author: "Alessandro Wiget"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Librerie

```{r, results='hide', warning= FALSE, message=FALSE}
library(readxl)
library(dplyr)
library( faraway )
library( leaps )
library(MASS)
library( GGally)
library(BAS)
library(rgl)
library(corrplot)
library(pscl)
library(plm)
```

## Il Dataset

Prima di tutto definiamo la working directory:

IMPORTANTE! Cambiare la directory a seconda del pc.

Importiamo il Dataset, presente nella cartella `Dati/`:

```{r}
setwd("C:/Users/sanni/OneDrive/Desktop/POLIMI/3 anno/inferenza/Progetto-Inferenza-Statistica-main")
df <- read_excel("./Dati/Dropout20240226_IngMate.xlsx")
#View(df)
```

## Regressione Logistica

Consideriamo innanzitutto solo gli studenti con carriere terminate, cioè o che si sono laureati o che hanno abbandonato il corso di studio:

```{r}
df$career_anonymous_id <- NULL
df$career_time <- NULL
df$stud_career_degree_start_id <- NULL
df$stud_career_degree_changed <- NULL
df$stud_career_degree_name <- NULL
df$stud_ofa_flst <- NULL
df$stud_ofa_fltp <- NULL
df$stud_career_degree_area <- NULL
df$stud_career_degree_code <- NULL
df$stud_career_degree_code_CdS <-NULL
df$highschool_type <- NULL
df$highschool_type_code <- NULL #abbiamo cancellato queste variabili operche possiamo separare fra classico, scientifico e altro con un'altra variabile
df$stud_admis_convent_start_dt <- NULL

filtered_df <- df %>% filter(stud_career_status != 'A')
```

Selezioniamo dal dataset le variabili numeriche:

```{r}
numerical_vars <- sapply(filtered_df, is.numeric)  # Find numeric columns
numerical_df <- filtered_df[, numerical_vars]  # Subset dataframe with numeric columns
numerical_df = na.omit(numerical_df)
```

Osserviamo se esistono correlazioni significative fra i dati numerici:

```{r}
X = numerical_df[, -4]
corrplot(cor(X), method='color')
```

Effettuiamo la regressione logistica fra le variabili numeriche del dataset:

```{r}
# Create a formula for linear model
formula <- as.formula(paste("dropout ~", paste(names(numerical_df[,-which(names(numerical_df) == "dropout")]), collapse = " + ")))

# Fit the linear model
model <- glm(formula, data = numerical_df, family=binomial)

# Print the summary of the model
summary(model)
```

Risultano rilevanti:

-   CFU conseguiti nel primo semestre, interpretabile nel seguente modo: chi passa tanti CFU al primo semestre ha più fiducia nel continuare il percorso per ovvi motivi.

-   gli anni dello studente/studentessa quando inizia l'università: chi inizia con ritardo e magari lavora già o ha anche altri interessi è più portato ad abbandonare il percorso.

-   La media dei voti pesa ragionevolmente per la stessa ragione del punto sui CFU

-   Per motivi da approfondire pesano l'anno di inizio e l'anno di fine, anche se ragionevolmente non ci sono differenze tra iniziare un percorso nel 2010 o nel 2023 (?)

-   Pesano molto inoltre il voto di uscita dalle superiori, quindi se uno era bravo/a alle superiori è probabile che lo sia anche all'univerisità

-   Pesa per quanto sei stato iscritto

-   Si noti che il test di ammissione alle lauree di ingegneria del Politecnico non risulta per niente predittivo della capacità dello studente di affrontare il percorso, almeno da questo dataset

Cerchiamo di trovare il miglior modello con un Automatic Selection Method. Massimizziamo l'adjr2 con la funzione `leaps()`, ovvero un algoritmo Branch and Bound per trovare tali modelli.

```{r, message=FALSE}
x = model.matrix( model ) [ , -1 ]
y = numerical_df$dropout

adjr = leaps( x, y, method = "adjr2" )
names(adjr)
```

```{r}
bestmodel_adjr2_ind = which.max( adjr$adjr2 )
adjr$which[ bestmodel_adjr2_ind, ] 

maxadjr(adjr,50)
```

Dal momento che non è presente una variazione significativa dell'adjr2 dei primi modelli, cerchiamo dunque di minimizzare il numero di variabili utilizzate. La scelta ricade dunque sul modello che contiene le features delle colonne `4,5,8,9`, covariate rilevanti anche nell'output generale.

Il modello diventa dunque:

```{r}
# Assuming 'df' is your dataframe and 'target' is your target variable
# Select only the columns you're interested in
selected_df <- numerical_df[, c(4,5,6,9,10)]

# Create a formula for the model
# This assumes that the first column is the target variable
formula <- paste("dropout ~", paste(names(selected_df[,-which(names(selected_df) == "dropout")]), collapse = " + "))

# Fit the model
model_opt <- glm(formula, data = selected_df, family = binomial)

# Print the summary of the model
summary(model_opt)

# adjr2 per il modello con interazione: (Usiamo McFadden)
pseudo_r2 <- pR2(model_opt)

pseudo_r2['McFadden']
```

Riferendoci alla tabella delle covariate presentata in precedenza, vogliamo capire se è possibile migliorare il modello introducendo una interazione fra le covariate che sono più correlate, ovvero `exa_cfu_pass` e `exa_grade_average`:

```{r}
# Assuming 'df' is your dataframe and 'target' is your target variable
# Select only the columns you're interested in
selected_df <- numerical_df[, c(4,5,6,9,10)]

# Create a formula for the model
# This assumes that the first column is the target variable
covariate <- paste("dropout ~", paste(names(selected_df[,-which(names(selected_df) == "dropout")]), collapse = " + "))

interazioni = " + exa_cfu_pass * exa_grade_average"

formula = as.formula(paste(covariate, interazioni))

# Fit the model
model_opt <- glm(formula, data = selected_df, family = binomial)

# Print the summary of the model
summary(model_opt)

# adjr2 per il modello con interazione: (Usiamo McFadden)
pseudo_r2 <- pR2(model_opt)

pseudo_r2['McFadden']
```

Notiamo un miglioramento dell'AIC, tuttavia adesso la feature `exa_cfu_pass` risulta superflua, procediamo quindi ad eliminarla:

```{r}
# Assuming 'df' is your dataframe and 'target' is your target variable
# Select only the columns you're interested in
selected_df <- numerical_df[, c(4,5,6,9,10)]

# Create a formula for the model
# This assumes that the first column is the target variable
covariate <- paste("dropout ~", paste(names(selected_df[,-which(names(selected_df) == "dropout")]), collapse = " + "))

interazioni = " + exa_cfu_pass * exa_grade_average"

rimuovere = "- exa_cfu_pass"

formula = as.formula(paste(covariate, interazioni, rimuovere))

# Fit the model
model_opt <- glm(formula, data = selected_df, family = binomial)

# Print the summary of the model
summary(model_opt)

# adjr2 per il modello con interazione: (Usiamo McFadden)
pseudo_r2 <- pR2(model_opt)

pseudo_r2['McFadden']
```

Confrontando i valori dell'adjusted R\^2 vediamo che l'aggiunta di una covariata data dal termine di interazione, fa aumentare l'indice di pochi millesimi. Dunque non risulta vantaggioso il tradeoff e manteniamo il modello precedente.

## Studio punti leva, outliers, collinearità

Valutiamo l'impatto sul modello di eventuali punti leva e outliers. Partiamo dai punti leva:

```{r}
Z=model.matrix(model_opt) #matrice disegno, i leverages su diag princ
# __Rule of thumb:__ Given a point h_ii diagonal element of H, the i-th observation is a leverage if:
#  h_ii > 2*(p)/n
lev=hat(Z) #h_ii
p = model_opt$rank #nro covariate+1  
n = dim(Z)[1] #nro osservazioni

#plot dei leverages in funzione dell'osservazione
plot( model_opt$fitted.values, lev, ylab = "Leverages", main = "Plot of Leverages", 
      pch = 16, col = 'black' )
abline( h = 2 * p/n, lty = 2, col = 'red' ) #COSTRUISCO LEVA PER VEDERE SE QUALCUNO SUPERA
watchout_points_lev = lev[ which( lev > 2 * p/n  ) ]
watchout_ids_lev = seq_along( lev )[ which( lev > 2 * p/n ) ] ## identify the rows relative to leverage points
points( model_opt$fitted.values[ watchout_ids_lev ], watchout_points_lev, col = 'red', pch = 16 )

sum( lev [ lev >  2 * p / n ] ) # 1.36234/5= 0.272468 i leverages pesano quasi il 30 percento

```

Provo a toglierli e a valutare se il modello risulta più esplicativo.

```{r}
# Create a formula for the model
# This assumes that the first column is the target variable
formula <- paste("dropout ~", paste(names(selected_df[,-which(names(selected_df) == "dropout")]), collapse = " + "))

# Fit the model
model_opt_nolev <- glm(formula, data = selected_df, family = binomial, subset = (lev< 2 * p / n))

# Print the summary of the model
summary(model_opt_nolev)

# adjr2 per il modello con interazione: (Usiamo McFadden)
pseudo_r2 <- pR2(model_opt_nolev)

pseudo_r2['McFadden']

abs( ( model_opt$coefficients - model_opt_nolev$coefficients ) / model_opt$coefficients ) #quanto variano i coefficienti
```

Il valore di McFadden risulta migliorato di circa 2 punti percentuali, ma ora la media risulta poco rilevante. Prima di considerare questo un buon modello cerchiamo di valutare i leverages più pesanti e motivare la loro rimozione. I coefficienti variano notevolmente nel caso dell' highschool_grade e del career_time_conv. C'è potenzialità di migliorare il modello comunque.

```{r}
colors = rep( 'black', nrow( selected_df ) )
colors[ watchout_ids_lev ] = c('red', 'blue', 'green', 'orange')

pairs( selected_df[ , c( 'dropout', 'exa_cfu_pass', 'exa_grade_average', 'highschool_grade', 'career_time_conv' ) ], 
       pch = 16, col = colors, cex = 1 + 0.5 * as.numeric( colors != 'black' ))
```

NO

Filtriamo un subset particolarmente rilevante di leverages e capiamo perchè potrebbero essere tolti dal dataset.

```{r}
impact_lev = lev[ which( lev > 2 * p/n  ) ]
impact_ids_lev = seq_along( lev )[ which( lev > 0.010) ] ## identify the rows relative to HEAVY leverage points
sum(lev[lev > 0.010]) #impatto di questi leverages del 12 percento, still rilevante
length(impact_ids_lev) #E SONO SOLO 10 quindi li posso studiare nel dettaglio
#vediamo un grafico
colors = rep( 'black', nrow( selected_df ) )
colors[ impact_ids_lev ] = c('red', 'blue', 'green', 'orange')

pairs( selected_df[ , c( 'dropout', 'exa_cfu_pass', 'exa_grade_average', 'highschool_grade', 'career_time_conv' ) ], 
       pch = 16, col = colors, cex = 1 + 0.5 * as.numeric( colors != 'black' ))
```

```{r}
impattanti=selected_df[impact_ids_lev, ]
impattanti
```

Il primo caso è uno studente che non ha dato nessun esame ed è rimasto iscritto al poli per più di sette anni. Lo stesso pattern è da evidenziare negli altri casi. Data la numerosità del campione e la particolarità di queste osservazioni rispetto al pattern medio, si ritiene opportuno eliminare tali osservazioni.

```{r}
# Create a formula for the model
# This assumes that the first column is the target variable
formula <- paste("dropout ~", paste(names(selected_df[,-which(names(selected_df) == "dropout")]), collapse = " + "))

# Fit the model
model_opt_noimpattanti <- glm(formula, data = selected_df[-impact_ids_lev,], family = binomial) 

# Print the summary of the model
summary(model_opt_noimpattanti)
#print AIC
AIC(model_opt)
AIC(model_opt_noimpattanti) 
#print McFadden
pseudo_r2 <- pR2(model_opt_nolev)

pseudo_r2['McFadden']
#quanto variano i coefficienti
abs( ( model_opt$coefficients - model_opt_noimpattanti$coefficients ) / model_opt$coefficients ) 
```

Notiamo un miglioramento dell'

```         
8.52185%
```

sull'AIC. Inoltre variano significativamente i coefficienti relativi all'highschool_grade e career_time_conv. Quest'ultimo giustificato dalle tempistiche anomale di questi studenti.

## Variabili Categoriche:

```{r}
filtered_df <- df %>% filter(stud_career_status != 'A')
filtered_df_no_na = na.omit(filtered_df)

new_df <- selected_df

new_df$stud_gender = factor(filtered_df_no_na$stud_gender, ordered = F)
new_df$previousStudies = factor(filtered_df_no_na$previousStudies, ordered = F)
new_df$origins = factor(filtered_df_no_na$origins, ordered = F)
new_df$income_bracket_normalized_on4 = factor(filtered_df_no_na$income_bracket_normalized_on4, ordered = F)
new_df$dropped_on_180 = factor(filtered_df_no_na$dropped_on_180, ordered = F)
# Create a formula for the model
# This assumes that the first column is the target variable
covariate <- paste("dropout ~", paste(names(new_df[,-which(names(new_df) == "dropout")]), collapse = " + "))

formula = as.formula(paste(covariate))

# Fit the model
model_opt <- glm(formula, data = new_df, family = binomial)

# Print the summary of the model
summary(model_opt)

# adjr2 per il modello con interazione: (Usiamo McFadden)
pseudo_r2 <- pR2(model_opt)

pseudo_r2['McFadden']
```

Cerchiamo di migliorare con una ricerca eliminando covariate:

```{r, message=FALSE}
covariate <- paste("dropout ~", paste(names(new_df[,-which(names(new_df) == "dropout")]), collapse = " + "))

delete = "- dropped_on_180 - origins -income_bracket_normalized_on4 "

formula = as.formula(paste(covariate, delete))

# Fit the model
model_opt <- glm(formula, data = new_df, family = binomial)

# Print the summary of the model
summary(model_opt)

# adjr2 per il modello con interazione: (Usiamo McFadden)
pseudo_r2 <- pR2(model_opt)

pseudo_r2['McFadden']
```

Introduciamo adesso delle interazioni per vedere se possiamo migliorare il risultato:

```{r, message=FALSE}
covariate <- paste("dropout ~", paste(names(new_df[,-which(names(new_df) == "dropout")]), collapse = " + "))

delete = "- dropped_on_180 - origins -income_bracket_normalized_on4"

interactions = "+stud_gender*exa_cfu_pass +stud_gender*exa_grade_average +stud_gender*highschool_grade +stud_gender*career_time_conv"

formula = as.formula(paste(covariate, interactions ,delete))

# Fit the model
model_opt <- glm(formula, data = new_df, family = binomial)

# Print the summary of the model
summary(model_opt)

# adjr2 per il modello con interazione: (Usiamo McFadden)
pseudo_r2 <- pR2(model_opt)

pseudo_r2['McFadden']
```

Faccio adesso un test per vedere il massimo teorico per quanto riguarda l'adjR2, aggiungendo quasi tutte le variabili possibili e semplificando con leaps():

```{r, message=FALSE}
covariate <- paste("dropout ~", paste(names(new_df[,-which(names(new_df) == "dropout")]), collapse = " + "))

interactions = "+income_bracket_normalized_on4*exa_cfu_pass +income_bracket_normalized_on4*exa_grade_average + income_bracket_normalized_on4*highschool_grade + income_bracket_normalized_on4*career_time_conv +income_bracket_normalized_on4*highschool_grade +income_bracket_normalized_on4*career_time_conv +dropped_on_180*exa_grade_average + dropped_on_180*highschool_grade + dropped_on_180*career_time_conv +dropped_on_180*highschool_grade +dropped_on_180*career_time_conv"

# +stud_gender*exa_cfu_pass +stud_gender*exa_grade_average + stud_gender*highschool_grade +stud_gender*highschool_grade +stud_gender*career_time_conv   
# +origins*exa_cfu_pass +origins*exa_grade_average + origins*highschool_grade + origins*career_time_conv +origins*highschool_grade + origins*career_time_conv
# +previousStudies*exa_cfu_pass +previousStudies*exa_grade_average + previousStudies*highschool_grade + previousStudies*career_time_conv +previousStudies*highschool_grade +previousStudies*career_time_conv

formula = as.formula(paste(covariate, interactions))

# Fit the model
model_opt <- glm(formula, data = new_df, family = binomial)

# Print the summary of the model
summary(model_opt)

# adjr2 per il modello con interazione: (Usiamo McFadden)
pseudo_r2 <- pR2(model_opt)

pseudo_r2['McFadden']
```

```{r, message=FALSE}
x = model.matrix( model_opt ) [ , -1 ]
y = new_df$dropout

detect.lindep(x) #"Suspicious column name(s):   exa_cfu_pass:dropped_on_180Y, exa_grade_average:dropped_on_180Y" (Cancellata la prima)

adjr = leaps( x, y, method = "adjr2" )
names(adjr)
```

```{r}
bestmodel_adjr2_ind = which.max( adjr$adjr2 )
adjr$which[ bestmodel_adjr2_ind, ] 

maxadjr(adjr,15)
```

```{r}
leap_matrix = data.frame(x[, c(1,2,3,4,5,6,8,12,13,14,15,22,23,24,25,26,27,28)])

leap_matrix$dropout = new_df$dropout

covariate <- paste("dropout ~", paste(names(leap_matrix[,-which(names(leap_matrix) == "dropout")]), collapse = " + "))

formula = as.formula(paste(covariate))

# Fit the model
model_leap <- glm(formula, data = leap_matrix, family = binomial)

# Print the summary of the model
summary(model_leap)

# adjr2 per il modello con interazione: (Usiamo McFadden)
pseudo_r2 <- pR2(model_leap)

pseudo_r2['McFadden']

```

## Ultima Idea

Fra il modello con tutte le variabili numeriche e quello con solo 4, accumuliamo un notevole AIC, proviamo a mantenere tutte le variabili numeriche e ad aggiungere le categorie:

```{r}
filtered_df <- df %>% filter(stud_career_status != 'A')
filtered_df_no_na = na.omit(filtered_df)

numerical_vars <- sapply(filtered_df, is.numeric)  # Find numeric columns
numerical_df <- filtered_df[, numerical_vars]  # Subset dataframe with numeric columns
general_df = na.omit(numerical_df)

general_df$stud_gender = factor(filtered_df_no_na$stud_gender, ordered = F)
general_df$previousStudies = factor(filtered_df_no_na$previousStudies, ordered = F)
general_df$origins = factor(filtered_df_no_na$origins, ordered = F)
general_df$income_bracket_normalized_on4 = factor(filtered_df_no_na$income_bracket_normalized_on4, ordered = F)
general_df$dropped_on_180 = factor(filtered_df_no_na$dropped_on_180, ordered = F)

covariate <- paste("dropout ~", paste(names(general_df[,-which(names(general_df) == "dropout")]), collapse = " + "))

formula = as.formula(paste(covariate))

# Fit the model
model_opt <- glm(formula, data = general_df, family = binomial)

# Print the summary of the model
summary(model_opt)

# adjr2 per il modello con interazione: (Usiamo McFadden)
pseudo_r2 <- pR2(model_opt)

pseudo_r2['McFadden']
```

```{r, message=FALSE}
x = model.matrix( model_opt ) [ , -1 ]
y = new_df$dropout

detect.lindep(x) #"Suspicious column name(s):   exa_cfu_pass:dropped_on_180Y, exa_grade_average:dropped_on_180Y" (Cancellata la prima)

adjr = leaps( x, y, method = "adjr2" )
names(adjr)
```

```{r}
bestmodel_adjr2_ind = which.max( adjr$adjr2 )
adjr$which[ bestmodel_adjr2_ind, ] 

maxadjr(adjr,15)
```

Siamo riusciti quindi a raggiungere un adjR2 = 0.652, meglio, per ora, non risulta possibile.

Qui sotto il modello:

```{r}
leap_matrix = data.frame(x[, c(1,2,3,4,5,6,7,8,9,10,11,13,17,18,19,20 )])
leap_matrix$dropout = new_df$dropout

covariate <- paste("dropout ~", paste(names(leap_matrix[,-which(names(leap_matrix) == "dropout")]), collapse = " + "))

formula = as.formula(paste(covariate))

# Fit the model
model_leap <- glm(formula, data = leap_matrix, family = binomial)

# Print the summary of the model
summary(model_leap)

# adjr2 per il modello con interazione: (Usiamo McFadden)
pseudo_r2 <- pR2(model_leap)

pseudo_r2['McFadden']

```

## Predizione

Applichiamo adesso il modello lineare sugli studenti che non hanno ancora completato il loro percorso universitario: (NON FUNZIONA, va sistemato)

```{r}
if(FALSE){
  # This is a block comment in R.
  # You can write multiple lines of comments here.
  # None of these lines will be executed.

filtered_df <- df %>% filter(stud_career_status == 'A')
filtered_df$dropout <-NULL
filtered_df$stud_career_end_ay <- NULL
filtered_df$stud_career_end_date <- NULL
filtered_df_no_na = na.omit(filtered_df)

new_data <- filtered_df_no_na

new_data$stud_gender = factor(filtered_df_no_na$stud_gender, ordered = F)
new_data$previousStudies = factor(filtered_df_no_na$previousStudies, ordered = F)
new_data$origins = factor(filtered_df_no_na$origins, ordered = F)
new_data$income_bracket_normalized_on4 = factor(filtered_df_no_na$income_bracket_normalized_on4, ordered = F)
new_data$dropped_on_180 = factor(filtered_df_no_na$dropped_on_180, ordered = F)

new_data$dropout <- NA
new_data <- new_data[names(new_df)]
new_data$dropout <- NULL

#new_data$dropped_on_180 <- NULL 

predicted_values <- predict(model_opt, newdata = new_data, type = "response")
plot(new_data$exa_cfu_pass, predicted_values, main="Predizione di dropout / CFU acquisiti nel primo semestre", 
     xlab="CFU sostenuti", 
     ylab="Predizione Dropout")

plot(new_data$exa_grade_average, predicted_values, main="Predizione di dropout / Media pesata nel primo semestre", 
     xlab="media pesata", 
     ylab="Predizione Dropout")
}
```
