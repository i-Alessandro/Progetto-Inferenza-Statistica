---
title: "Regressione_new"
author: "Alessandro Wiget"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Librerie

```{r, results='hide', warning= FALSE, message=FALSE}
library(readxl)
library(dplyr)
library( faraway )
library( leaps )
library(MASS)
library( GGally)
library(BAS)
library(rgl)
library(corrplot)
library(pscl)
library(plm)
library(glmulti)
library(AICcmodavg)
```

## Il Dataset

Prima di tutto definiamo la working directory:

IMPORTANTE! Cambiare la directoy a seconda del pc.

Importiamo il Dataset, presente nella cartella `Dati/`:

```{r}
setwd("/home/alessandro/Inferenza Statistica/Progetto/Code")
df <- read_excel("../Dati/Dropout20240226_IngMate.xlsx")
#View(df)
```

## Regressione Logistica

Consideriamo innanzitutto solo gli studenti con carriere terminate, cioè o che si sono laureati o che hanno abbandonato il corso di studio:

```{r}
df$career_anonymous_id <- NULL
df$career_time <- NULL
df$stud_career_degree_start_id <- NULL
df$stud_career_degree_changed <- NULL
df$stud_career_degree_name <- NULL
df$stud_ofa_flst <- NULL
df$stud_ofa_fltp <- NULL
df$stud_career_degree_area <- NULL
df$stud_career_degree_code <- NULL
df$stud_career_degree_code_CdS <-NULL
df$highschool_type <- NULL
df$highschool_type_code <- NULL #abbiamo cancellato queste variabili operche possiamo separare fra classico, scientifico e altro con un'altra variabile
df$stud_admis_convent_start_dt <- NULL

filtered_df <- df %>% filter(stud_career_status != 'A')
```

Selezioniamo dal dataset le variabili numeriche:

```{r}
numerical_vars <- sapply(filtered_df, is.numeric)  # Find numeric columns
numerical_df <- filtered_df[, numerical_vars]  # Subset dataframe with numeric columns
numerical_df = na.omit(numerical_df)
```

Osserviamo se esistono correlazioni significative fra i dati numerici:

```{r}
X = numerical_df[, -4]
corrplot(cor(X), method='color')
```

## La Prima Regressione Logistica

Effettuiamo la regressione logistica fra le variabili numeriche del dataset, e vediamo quanto vale inizialmente l'adjustedR2:

```{r}
# Create a formula for linear model
formula_num <- as.formula(paste("dropout ~", paste(names(numerical_df[,-which(names(numerical_df) == "dropout")]), collapse = " + ")))

# Fit the linear model
model_init <- glm(formula_num, data = numerical_df, family=binomial)

# Print the summary of the model
summary(model_init)

pseudo_r2 <- pR2(model_init)

pseudo_r2['McFadden']
```
Iniziamo da un valore di adjustedR2 di 0.656, quindi già buono, vediamo adesso di trovare un buon modello logistico, che dunque minimizzi l'AIC.

Utilizziamo un Automatic Selection Method. Minimizziamo l'AIC con la funzione `glmulti()`, presente nell'omonima libreria.

```{r, message=FALSE}
glmulti.logistic.out <-
    glmulti(formula_num, data = numerical_df,
            level = 1,               # No interaction considered
            method = "h",            # Exhaustive approach
            crit = "aic",            # AIC as criteria
            confsetsize = 25,         # Keep 5 best models
            plotty = T, report = T,  # plot or interim reports
            fitfunction = "glm",     # glm function
            family = binomial)       # binomial family for logistic regression

## Show 5 best models (Use @ instead of $ for an S4 object)
glmulti.logistic.out@formulas
```
Restringiamoci al miglior modello per ogni numero di variabli (l'intercetta conta come variabile extra), e mostriamo anche i rispettivi adjustedR2:

```{r}
model_opt_7 = glm("dropout ~ 1 + career_start_ay + stud_career_admission_age + exa_cfu_pass + 
    exa_grade_average + stud_career_end_ay + highschool_grade + 
    career_time_conv", data=numerical_df, family=binomial)

model_opt_6 = glm("dropout ~ 1 + career_start_ay + exa_cfu_pass + exa_grade_average + 
    stud_career_end_ay + highschool_grade + career_time_conv", data=numerical_df, family=binomial)

model_opt_5 = glm("dropout ~ 1 + career_start_ay + exa_cfu_pass + stud_career_end_ay + 
    highschool_grade + career_time_conv", data=numerical_df, family=binomial)

models  = list(model_init, model_opt_7, model_opt_6, model_opt_5)
model.names = c('Modello iniziale', 'Modello Ottimo con 7 Var', 'Modello Ottimo con 6 Var', 'Modello Ottimo con 5 Var')
aictab(cand.set = models, modnames = model.names)

print("Pseudo-R2 values:")
sprintf("model_init: %f", pR2(model_init)['McFadden'])
sprintf("model_opt_7: %f", pR2(model_opt_7)['McFadden'])
sprintf("model_opt_6: %f", pR2(model_opt_6)['McFadden'])
sprintf("model_opt_5: %f", pR2(model_opt_5)['McFadden'])
```
Non notiamo un  peggioramento troppo elevato né dell'AIC né dell'adjR2 utilizzando il modello a 5 covariate,  quindi prendiamo in considerazione quest'ultimo. 

Effettuiamo una ricerca backward dal modello finale per cercare di trovare un modello simile ma con un processo più logico. 

```{r}
covariate = paste("dropout ~", paste(names(numerical_df[,-which(names(numerical_df) == "dropout")]), collapse = " + "))

#Covariate rimosse durante la semplificazione, in ordine
rimosso =  paste("- stud_admission_score - exa_avg_attempts - stud_career_admission_age - exa_grade_average")

formula_num <- as.formula(paste(covariate, rimosso))

# Fit the linear model
model_back <- glm(formula_num, data = numerical_df, family=binomial)

# Print the summary of the model
summary(model_back)

pseudo_r2 <- pR2(model_back)

pseudo_r2['McFadden']

model_opt = model_back
```


In relazione alla matrice delle covariate descritta prima `career_start_ay` e `stud_career_end_ay` sono estremamente correlate, vediamo se otteniamo un miglioramento o un peggioramento cancellandone una alla volta:

```{r}
model_no_start = glm("dropout ~ 1 + stud_career_admission_age + exa_cfu_pass + 
    exa_grade_average + stud_career_end_ay + highschool_grade + 
    career_time_conv", data=numerical_df, family=binomial)

model_no_end = glm("dropout ~ 1 + career_start_ay + stud_career_admission_age + exa_cfu_pass + 
    exa_grade_average  + highschool_grade + 
    career_time_conv ", data=numerical_df, family=binomial)

models  = list(model_init, model_opt, model_no_start, model_no_end)
model.names = c('Modello iniziale', 'Modello Ottimo', 'Modello Senza Anno di Inizio', 'Modello Senza Anno di Fine')
aictab(cand.set = models, modnames = model.names)
```

Abbiamo un peggioramento sia se eliminiamo `career_start_ay` che se eliminiamo `stud_career_end_ay`, decidiamo, per ora, di mantenere invariato il modello.

## Introduzione Interazioni fra Variabili Numeriche

Prima di procedere con l'aggiunta di variabili categoriche cerchiamo di comprendere se le aggiunte di interazioni fra variabili numeriche ci permettono di migliorare il nostro modello. 
Osservando la matrice delle covariate costruita all'inizio possiamo osservare che `career_start_ay` e `stud_career_end_ay` sono estremamente correlate, aggiungiamo quindi al modello: `career_start_ay*stud_career_end_ay`. 
Seguendo lo stesso ragionamento un'altra coppia di covariate che appaiono essere molto correlate sono `exa_cfu_pass` e `exa_grade_average`, introduciamo la loro interazione `exa_cfu_pass*exa_grade_average`:

```{r}
model_int_years = glm("dropout ~ 1 + stud_career_admission_age + exa_cfu_pass + 
    exa_grade_average + highschool_grade + 
    career_time_conv + career_start_ay*stud_career_end_ay", data=numerical_df, family=binomial)

model_int_grades = glm("dropout ~ 1 + stud_career_admission_age + highschool_grade + 
    career_time_conv + career_start_ay*stud_career_end_ay + 
    exa_cfu_pass*exa_grade_average", data=numerical_df, family=binomial)

models  = list(model_init, model_opt, model_int_years, model_int_grades)
model.names = c('Modello iniziale', 'Modello Ottimo',  'Modello con Interazione fra Anni', 'Modello con Interazione fra CFU e Medie')
aictab(cand.set = models, modnames = model.names)
```
Otteniamo un buon miglioramento dell'AIC a fronte di una maggiore complessità del modello (Decidere se mantenere o no il nuovo modello).
```{r}
#Aggiorniamo il migliore modello che  abbiamo trovato finora
model_opt_int = model_int_grades
```

## Introduzione delle Variabili Categoriche

Rendiamo tutte le variabili del Dataset di tipo `factor` affinchè siano utilizzabili nella regressione logistica.

```{r}
filtered_df <- df %>% filter(stud_career_status != 'A')
filtered_df_no_na = na.omit(filtered_df)

#Partendo dal modello di ottimo trovato prima costruisco la matrice solo con quelle covariate:
new_df <- numerical_df
new_df$stud_admission_score <- NULL
new_df$exa_avg_attempts <- NULL

new_df$stud_gender = factor(filtered_df_no_na$stud_gender, ordered = F)
new_df$previousStudies = factor(filtered_df_no_na$previousStudies, ordered = F)
new_df$origins = factor(filtered_df_no_na$origins, ordered = F)
new_df$income_bracket_normalized_on4 = factor(filtered_df_no_na$income_bracket_normalized_on4, ordered = F)
new_df$dropped_on_180 = factor(filtered_df_no_na$dropped_on_180, ordered = F)

#Costruiamo un modello con tutte le variabili categoriche:
covariate = paste("dropout ~", paste(names(new_df[,-which(names(new_df) == "dropout")]), collapse = " + "))
interazioni = "+ exa_cfu_pass*exa_grade_average"
formula_cat <- as.formula(paste(covariate, interazioni))

model_cat <- glm(formula_cat, data = new_df, family=binomial)

summary(model_cat)

models  = list(model_init, model_opt, model_cat, model_opt_int)
model.names = c('Modello iniziale', 'Modello Ottimo', 'Modello con Ottimo con Interazione + Categorie', 'Modello Ottimo con Interazione')
aictab(cand.set = models, modnames = model.names)
```



**Qui bisogna introdurre i risultati delle analisi fatte con ANOVA, per capire quali categorie sono effettivamente importanti e che hanno bisogno di essere considerate. Poi procediamo con una ricerca del modello che minimizza l'AIC includendo le variabili categoriche.**

**Lo step di minimizzazione lo possiamo cancellare una volta che abbiamo ridotto la numerosità di variabili categoriche con l'ANOVA**

Proviamo a migliorarlo con `glmulti()`:

```{r, message=FALSE}
glmulti.logistic.out <-
    glmulti(formula_cat, data = new_df,
            level = 1,               # No interaction considered
            method = "h",            # Exhaustive approach
            crit = "aic",            # AIC as criteria
            confsetsize = 5,         # Keep 5 best models
            plotty = F, report = F,  # No plot or interim reports
            fitfunction = "glm",     # glm function
            family = binomial)       # binomial family for logistic regression

## Show 5 best models (Use @ instead of $ for an S4 object)
glmulti.logistic.out@formulas
```
Notiamo che il modello suggerito contiene la variabile categorica `stud_gender`. 
Osserviamo il modello ottimale trovato e compariamolo al modello iniziale,  al modello ottimale trovato finora e a quest'ultimo con l'aggiunta di `stud_gender`:

```{r}
model_opt_cat = glm("dropout ~ 1 + stud_gender + career_start_ay + stud_career_admission_age + 
    exa_cfu_pass + exa_grade_average + stud_career_end_ay + highschool_grade + 
    career_time_conv", data=new_df, family=binomial)

model_opt_stud_gender = glm("dropout ~ 1 + stud_career_admission_age + highschool_grade + 
    career_time_conv + career_start_ay*stud_career_end_ay + 
    exa_cfu_pass*exa_grade_average + stud_gender ", data=new_df, family=binomial)

models  = list(model_init, model_opt, model_opt_cat, model_opt_stud_gender)
model.names = c('Modello iniziale', 'Modello Ottimizzato', 'Modello con Categorie Ottimizzato', 'Modello Ottimo + Categoria stud_gender')
aictab(cand.set = models, modnames = model.names)
```
Rigettiamo quindi il modello 

## Introduzione delle Interazioni
