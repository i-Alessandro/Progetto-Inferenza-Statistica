---
title: "Regressione Logistica Senza Parametro Temporale"
author: "Alessandro Wiget, Sofia Sannino, Pietro Masini, Giulia Riccardi"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Librerie

```{r, results='hide', warning= FALSE, message=FALSE}
library(readxl)
library(dplyr)
library( faraway )
library( leaps )
library(MASS)
library( GGally)
library(BAS)
library(rgl)
library(corrplot)
library(pscl)
library(plm)
#library(glmulti)
library(AICcmodavg)
#library(glmtoolbox)
library(caret)
library(pROC)
library(e1071)
library(stats)
setwd("C:/Users/sanni/OneDrive/Desktop/POLIMI/3 anno/inferenza/Progetto-Inferenza-Statistica-main")
```

## Il Dataset

Prima di tutto definiamo la working directory:

IMPORTANTE! Cambiare la directoy a seconda del pc.

Importiamo il Dataset, presente nella cartella `Dati/`:

```{r}
setwd("C:/Users/sanni/OneDrive/Desktop/POLIMI/3 anno/inferenza/Progetto-Inferenza-Statistica-main")
library(readxl)
df <- read_excel("Dati/Dropout20240226_IngMate.xlsx")
#View(df)
```

## Analisi esplorativa

-   L'obiettivo è quello di prevedere se una persona lascerà l'università o meno, basandosi principalemente sui dati che caratterizzano la sua carriera al primo semestre del primo anno. E' infatti ragionevole pensare che tali dati possano contenere elementi predittivi rilevanti, ai fini di un'azione mirata a limitare il dropout, il che avviene ragionevolemente all'inizio della carriera accademica.

-   **Dato che la variabile dipendente è bernoulliana (yi_hat ∈ {0,1} e pi_hat ∈ [0,1]) , sappiamo che dovremo costruire un modello di regressione logistica.**

-   Consideriamo perciò solo gli studenti con carriere terminate, cioè o che si sono laureati o che hanno abbandonato il corso di studio.

```{r}

#togliamo covariate inutili, togliamo gli attivi dei quali non sappiamo ancora se hanno droppato o no.
df$career_anonymous_id <- NULL
df$career_time <- NULL
df$stud_career_degree_start_id <- NULL
df$stud_career_degree_changed <- NULL
df$stud_career_degree_name <- NULL
df$stud_ofa_flst <- NULL
df$stud_ofa_fltp <- NULL
df$stud_career_degree_area <- NULL
df$stud_career_degree_code <- NULL
df$stud_career_degree_code_CdS <-NULL
df$highschool_type <- NULL
df$highschool_type_code <- NULL #abbiamo cancellato queste variabili perchè possiamo separare fra classico, scientifico e altro con un'altra variabile
df$stud_admis_convent_start_dt <- NULL
df$stud_career_end_ay <-NULL
#teniamo solo le persone che non sono attive e delle quali sappiamo già se hanno droppato o no
filtered_df <- df %>% filter(stud_career_status != 'A')
```

-   Selezioniamo inizialmente dal dataset le variabili numeriche.

-   In particolare togliamo la variabile career_time che indica i giorni per cui si è stati iscritti al poli, poichè risulta equivalente a livello interpretativo alla variabile bernoulliana del dropout, dando in questo modo problemi a livello di previsione, oltre ad essere in determinati casi fuori contesto per quanto riguarda lo scopo della ricerca.

```{r}
numerical_vars <- sapply(filtered_df, is.numeric)  # Find numeric columns
numerical_df <- filtered_df[, numerical_vars]  # Subset dataframe with numeric columns
numerical_df = na.omit(numerical_df)

#analisi esplorativa dei dati: notiamo che ci sono persone che non hanno iniziato il poli e in più ci sono persone che sono iscritte da 3 anni o più 

plot(numerical_df$exa_cfu_pass, numerical_df$career_time_conv)
abline( h=1200, lty = 2, col = 'red' )
#RITENIAMO A QUESTO PUNTO LA VARIABILE TEMPO NON RILEVANTE PERCHE' A NOI INTERESSA PREVEDERE IL DROPOUT ED EVITARLO, PROGETTANDO UN'AZIONE BASATA SU DATI DEL PRIMO SEMESTRE DEL PRIMO ANNO E PORTATA AVANTI IMMEDIATATAMENTE IL PRIMO ANNO STESSO. IL FATTO CHE LA CARRIERA DURI PIU O MENO E' FUORI CONTESTO: NOI VOGLIAMO CHE Y=0. 
numerical_df = numerical_df[which(!((numerical_df$career_time_conv > 1000 & numerical_df$exa_cfu_pass==0)| numerical_df$career_time_conv<0)),] 
#numerical_df = numerical_df[which(!(numerical_df$career_time_conv<0)),]
numerical_df$career_time_conv <- NULL

#View(numerical_df)
```

Osserviamo se esistono correlazioni significative fra i dati numerici:

```{r}
X = numerical_df[, -4]
corrplot(cor(X), method='color')
```

Notiamo una correlazione importante tra cfu sostenuti e media esami e tra media esami e tentativi medi esami.

```{r}
min(numerical_df$exa_cfu_pass)
max(numerical_df$exa_cfu_pass)

x  = c( 0, 7, 10, 17, 20, 27, 40) #supporto cfu

# Calcoliamo i punti medi degli intervalli che abbiamo creato
mid = c( ( x [ 2:7 ] + x [ 1:6 ] )/2 )

# Suddividiamo i dati nelle classi che abbiamo creato
GRAGE = cut( numerical_df$exa_cfu_pass, breaks = x, include.lowest = TRUE, right = FALSE )
GRAGE

# Calcoliamo quindi la media della variabile AGE stratificata e sovrapponiamo 
# i valori di y al grafico precedente.

y = tapply( numerical_df$dropout, GRAGE, mean )
y


plot( numerical_df$exa_cfu_pass, numerical_df$dropout, pch = ifelse( numerical_df$dropout  == 1, 3, 4 ),
col = ifelse( numerical_df$dropout== 1, 'forestgreen', 'red' ),
xlab = 'cfu', ylab = 'dropout', main = 'cfu vs. dropout', lwd = 2, cex = 1.5 )
points( mid, y, col = "blue", pch = 16 )

```

Notiamo qualitativamente che al diminuire dei cfu acquisiti nel primo semestre aumenta la probabilità di dropout.

## La Prima Regressione Logistica

Effettuiamo la regressione logistica fra le variabili numeriche del dataset, e vediamo quanto vale inizialmente lo pseudo adjustedR2 (indice di McFadden):

```{r}


# Create a formula for linear model
formula_num <- as.formula(paste("dropout ~", paste(names(numerical_df[,-which(names(numerical_df) == "dropout")]), collapse = " + ")))

# Fit the linear model
model_init <- glm(formula_num, data = numerical_df, family=binomial( link = logit ))

# Print the summary of the model
summary(model_init)

pseudo_r2 <- pR2(model_init)

pseudo_r2['McFadden']
```

Iniziamo da un modello con uno pseudo adjusted R\^2 relativamente buono.

Le covariate con p-value rilevanti sono:

-   exa_cfu_pass: il numero di cfu sostenuti nel primo semestre

-   exa_grade_average: la media dei voti del primo semestre

Notiamo inoltre che il modello presenta molte covariate non significative, pertanto operiamo una ricerca backward per eliminare quelle non rilevanti.

```{r}
covariate = paste("dropout ~", paste(names(numerical_df[,-which(names(numerical_df) == "dropout")]), collapse = " + "))

#Covariate rimosse durante la semplificazione, in ordine

formula_num <- as.formula(covariate)

# Fit the linear model
model_back <- glm(formula_num, data = numerical_df, family=binomial)

# Print the summary of the model
drop1(model_back, test="Chisq")
AIC(model_back)
#--------------------------------
model_back = update(model_back, . ~ . - career_start_ay)

# Print the summary of the model
drop1(model_back, test="Chisq")
AIC(model_back)
#-----------------------------
model_back = update(model_back, . ~ . - stud_admission_score)

# Print the summary of the model
drop1(model_back, test="Chisq")
AIC(model_back)
#-------------------------------
model_back = update(model_back, . ~ . - highschool_grade)

# Print the summary of the model
drop1(model_back, test="Chisq")
AIC(model_back)
#-------------------------------
model_back = update(model_back, . ~ . - stud_career_admission_age)

# Print the summary of the model
drop1(model_back, test="Chisq")
AIC(model_back)
#-------------------------------
model_back = update(model_back, . ~ . - exa_avg_attempts)

# Print the summary of the model
drop1(model_back, test="Chisq")
AIC(model_back)
#-------------------------------

```

Il modello risultante presenta due covariate numeriche significative: la media esami relativa al primo semestre e i cfu sostenuti al primo semestre.

## Analisi dei Punti Influenti #da levare?

Valutiamo l'impatto sul modello di eventuali punti leva. Partiamo dai punti leva:

```{r}
model_1=model_back
Z=model.matrix(model_1) #matrice disegno, i leverages su diag princ
# __Rule of thumb:__ Given a point h_ii diagonal element of H, the i-th observation is a leverage if:
#  h_ii > 2*(p)/n
lev=hat(Z) #h_ii
p = model_1$rank #nro covariate+1  
n = dim(Z)[1] #nro osservazioni

#plot dei leverages in funzione dell'osservazione
plot(model_1$fitted.values, lev, ylab = "Leverages", main = "Plot of Leverages", 
      pch = 16, col = 'black' )
abline( h = 2 * p/n, lty = 2, col = 'red' ) #COSTRUISCO LEVA PER VEDERE SE QUALCUNO SUPERA
watchout_points_lev = lev[ which( lev > 2 * p/n  ) ]
watchout_ids_lev = seq_along( lev )[ which( lev > 2 * p/n ) ] ## identify the rows relative to leverage points
points( model_1$fitted.values[ watchout_ids_lev ], watchout_points_lev, col = 'red', pch = 16 )

sum( lev [ lev >  2 * p / n ] ) # 1.36234/5= 0.272468 i leverages pesano quasi il 30 percento
colors = rep( 'black', nrow( numerical_df ) )
colors = rep( 'black', nrow( numerical_df ) )
colors[ watchout_ids_lev ] = c('red', 'blue', 'green', 'orange')
pairs( numerical_df[ , c( 'dropout', 'exa_cfu_pass', 'exa_grade_average' ) ], 
       pch = 16, col = colors, cex = 1 + 0.5 * as.numeric( colors != 'black' ))


#View(numerical_df)
```

Dal grafico dei punti leva, notiamo che esistono vari pattern degli studenti in base alle possibili combinazioni di cfu sostenuti al primo semestre (0, 7, 10, 17, 27).

```{r}

mod=glm("dropout~1+exa_cfu_pass+exa_grade_average",data = numerical_df, family=binomial)
summary(mod)


```

## Introduzione Interazioni fra Variabili Numeriche

Prima di procedere con l'analisi delle variabili categoriche cerchiamo di comprendere se le aggiunte di interazioni fra variabili numeriche ci permettono di migliorare il nostro modello. Osservando la matrice delle covariate costruita all'inizio si rileva che `exa_cfu_pass` e `exa_grade_average` sono molto correlate, pertanto aggiungo il termine di interazione al modello e successivamente valuto l'equivalenza o meno dei due modelli tramite il test ANOVA (Chiquadro):

```{r}
mod_int = update(mod, . ~ . + exa_cfu_pass*exa_grade_average)

summary(mod_int)
anova(mod, mod_int, test="Chisq")


```

Il p-value della covariata relativa al termine di interazione è alto pertanto non è significativa, inoltra il p-value alto del test di confronto indica che i due modelli sono equivalenti, pertanto seleziono quello più parsimonioso.

## Introduzione delle Variabili Categoriche

Rendiamo tutte le variabili del Dataset di tipo `factor` affinchè siano utilizzabili nella regressione logistica.

```{r}
MODEL = mod

filtered_df <- df %>% filter(stud_career_status != 'A')
filtered_df_no_na = na.omit(filtered_df)

#Partendo dal modello di ottimo trovato prima costruisco la matrice solo con quelle covariate:
cat_df <- filtered_df_no_na

cat_no_lev_df = cat_df[which(!((cat_df$career_time_conv > 1000 & cat_df$exa_cfu_pass==0)| cat_df$career_time_conv<0 | cat_df$career_time_conv>1600)),]
#cat_no_lev_df=cat_df[which(!(cat_df$career_time_conv<0)),]
cat_no_lev_df$career_time_conv <- NULL

cat_no_lev_df$stud_gender = factor(cat_no_lev_df$stud_gender, ordered=F)
cat_no_lev_df$previousStudies = factor(cat_no_lev_df$previousStudies, ordered=F)
cat_no_lev_df$origins = factor(cat_no_lev_df$origins, ordered=F)
cat_no_lev_df$income_bracket_normalized_on4 = factor(cat_no_lev_df$income_bracket_normalized_on4, ordered=F)


cat_no_lev_df$dropped_on_180<-NULL
cat_no_lev_df$stud_career_status <-NULL


#View(cat_no_lev_df)
```

Aggiorno il modello considerando le variabili categoriche, facendo un test di backward.

```{r}
model_cat = glm("dropout ~ 1 + 
    exa_cfu_pass + exa_grade_average  +stud_gender + previousStudies + origins + income_bracket_normalized_on4", data=cat_no_lev_df, family=binomial)

drop1(model_cat, test="Chisq")

model_cat = update(model_cat,  . ~ . - origins)
drop1(model_cat, test="Chisq")


model_cat = update(model_cat,  . ~ . - income_bracket_normalized_on4)
drop1(model_cat, test="Chisq")

summary(model_cat)
pseudo_r2 <- pR2(model_cat)

pseudo_r2['McFadden']

```

Abbiamo rilevato che le variabili categoriche previousStudies e stud_gender sono significative, mentre le origini dello studente e la sua fascia di reddito no. Inoltre McFadden migliora, pertanto aumenta la bontà del modello.

## Confusion Matrix

Eseguiamo ora la classificazione.

-    Computiamo la confusion matrix.

-   Splittiamo il dataset in due parti: il training set che comprende l'80% dei dati, il test set il restante 20%. Rifittiamo il modello sul training set e facciamo predizione sul test set.

-   Costruiamo la curva ROC e valutiamo la soglia ottimale.

```{r}


# Assume you have a dataframe data with predictors and a response variable
# split the data into train and test
set.seed(123)
trainIndex <- createDataPartition(cat_no_lev_df$dropout, p = 0.8, 
                                  list = FALSE, 
                                  times = 1)

train <- cat_no_lev_df[ trainIndex,]
test  <- cat_no_lev_df[-trainIndex,]

# Fit the logistic regression model
fit <- glm("dropout ~ 1 + exa_cfu_pass + exa_grade_average + previousStudies + stud_gender", data = train, family = binomial)

# Make predictions on the test set
predicted_probs <- predict(fit, newdata = test, type = "response")
#

# Compute the confusion matrix
#predicted_classes <- ifelse(predicted_probs > 0.5, 1, 0)
#cm <- confusionMatrix(predicted_classes, test$response)
#print(cm)

# Compute the ROC curve
roc_obj <- roc(test$dropout, predicted_probs)

# Plot the ROC curve
plot(roc_obj, print.auc = TRUE)

# Compute the AUC
auc <- auc(roc_obj)
print(auc)

#trovare soglia opt
best=coords(roc_obj, "best", ret="threshold", best.method="youden") #verificare
print(best)
#
test$dropout=as.factor(test$dropout)

# Compute the confusion matrix
predicted_classes <- ifelse(predicted_probs > as.numeric(best), 1, 0)
predicted_classes=as.factor(predicted_classes)

cm <- confusionMatrix(predicted_classes, test$dropout)
print(cm)

```

L'indice AUC, la sensitività, la specificità e la precisione sono tutti valori soddisfacenti.

## Predizione sugli studenti in corso:

Costruiamo il dataset degli studenti attivi, quindi quelli ancora in corso:

```{r}
attivi_df <- df %>% filter(stud_career_status == 'A')
attivi_df$dropout <- NULL

attivi_df$stud_career_end_date <- NULL
attivi_df = na.omit(attivi_df)
#attivi_df = attivi_df[which(!((attivi_df$career_time_conv > 1000 & attivi_df$exa_cfu_pass==0) | attivi_df$career_start_ay!=2023 | attivi_df$career_time_conv<177)),]
attivi_df = attivi_df[which((attivi_df$career_start_ay==2023)),]
attivi_df$stud_gender = factor(attivi_df$stud_gender, ordered=F)
attivi_df$previousStudies = factor(attivi_df$previousStudies, ordered=F)

#View(attivi_df)
```

Il modello ottimale è il seguente:

```{r}
model_opt = glm("dropout ~ 1 + exa_cfu_pass + exa_grade_average + previousStudies + stud_gender", data = train, family=binomial)
summary(model_opt)

```

Eseguiamo la predizione sugli studenti attivi presenti nel nostro modello, utilizzando il valore di threshold precedentemente trovato:

```{r}
predizione <- predict(model_opt, newdata = attivi_df, type = "response")

binary_output <- ifelse(predizione > as.numeric(best), 1, 0)

attivi_df$dropout_prediction = binary_output

sum(binary_output)/length(binary_output)

#View(attivi_df)
```

La probabilità di dropout stimata è 0.36, che sovrastima quella rilevata sugli studenti a carriera conclusa (mean(predicted_probs)=25.63 %). Questo è ragionevole considerando che l'obiettivo è prevenire il dropout, quindi in un'ottica di prevenzione, una sovrastima è accettabile.
